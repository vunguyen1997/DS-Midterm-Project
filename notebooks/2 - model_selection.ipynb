{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection\n",
    "\n",
    "This notebook should include preliminary and baseline modeling.\n",
    "- Try as many different models as possible.\n",
    "- Don't worry about hyperparameter tuning or cross validation here.\n",
    "- Ideas include:\n",
    "    - linear regression\n",
    "    - support vector machines\n",
    "    - random forest\n",
    "    - xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/vunguyen/DS-Midterm-Project/notebooks\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1. Load processed data from Part 1\n",
    "\n",
    "X_train = pd.read_csv(\"../data/processed/X_train.csv\")\n",
    "X_test  = pd.read_csv(\"../data/processed/X_test.csv\")\n",
    "y_train = pd.read_csv(\"../data/processed/y_train.csv\").squeeze()\n",
    "y_test  = pd.read_csv(\"../data/processed/y_test.csv\").squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔️ LinearRegression trained\n",
      "✔️ Ridge (α=1) trained\n",
      "✔️ Lasso (α=0.1) trained\n",
      "✔️ SVR (RBF) trained\n",
      "✔️ RandomForest trained\n",
      "✔️ XGBoost trained\n"
     ]
    }
   ],
   "source": [
    "# import models and fit\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# 1) select only numeric columns\n",
    "num_cols    = X_train.select_dtypes(include=[np.number]).columns\n",
    "X_train_num = X_train[num_cols].copy()\n",
    "X_test_num  = X_test[num_cols].copy()\n",
    "\n",
    "# 2) fit a median imputer on train and transform both train+test\n",
    "imp = SimpleImputer(strategy=\"median\")\n",
    "X_train_num[:] = imp.fit_transform(X_train_num)\n",
    "X_test_num[:]  = imp.transform(X_test_num)\n",
    "\n",
    "# 3) train models without NaN errors\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_num, y_train)\n",
    "    print(f\"✔️ {name} trained\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider what metrics you want to use to evaluate success.\n",
    "- If you think about mean squared error, can we actually relate to the amount of error?\n",
    "- Try root mean squared error so that error is closer to the original units (dollars)\n",
    "- What does RMSE do to outliers?\n",
    "- Is mean absolute error a good metric for this problem?\n",
    "- What about R^2? Adjusted R^2?\n",
    "- Briefly describe your reasons for picking the metrics you use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>42299.420281</td>\n",
       "      <td>12209.684555</td>\n",
       "      <td>0.985610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>84998.677352</td>\n",
       "      <td>52161.202357</td>\n",
       "      <td>0.941894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ridge (α=1)</td>\n",
       "      <td>294775.896769</td>\n",
       "      <td>181173.492160</td>\n",
       "      <td>0.301157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lasso (α=0.1)</td>\n",
       "      <td>294786.984737</td>\n",
       "      <td>181217.234693</td>\n",
       "      <td>0.301105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>294787.044930</td>\n",
       "      <td>181217.430887</td>\n",
       "      <td>0.301104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVR (RBF)</td>\n",
       "      <td>360367.814059</td>\n",
       "      <td>206254.002152</td>\n",
       "      <td>-0.044450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              model           RMSE            MAE        R2\n",
       "0      RandomForest   42299.420281   12209.684555  0.985610\n",
       "1           XGBoost   84998.677352   52161.202357  0.941894\n",
       "2       Ridge (α=1)  294775.896769  181173.492160  0.301157\n",
       "3     Lasso (α=0.1)  294786.984737  181217.234693  0.301105\n",
       "4  LinearRegression  294787.044930  181217.430887  0.301104\n",
       "5         SVR (RBF)  360367.814059  206254.002152 -0.044450"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gather evaluation metrics and compare results\n",
    "\n",
    "# 1) Import metrics\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 2) Define a small helper to compute all metrics\n",
    "def evaluate(name, y_true, y_pred):\n",
    "    mse  = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae  = mean_absolute_error(y_true, y_pred)\n",
    "    r2   = r2_score(y_true, y_pred)\n",
    "    return {\n",
    "        \"model\": name,\n",
    "        \"RMSE\": rmse,\n",
    "        \"MAE\":  mae,\n",
    "        \"R2\":   r2\n",
    "    }\n",
    "\n",
    "# 3) Loop through the trained models and collect results\n",
    "results = []\n",
    "for name, model in models.items():\n",
    "    preds = model.predict(X_test_num)     # or X_test_ohe if you OHE’d\n",
    "    results.append(evaluate(name, y_test, preds))\n",
    "\n",
    "# 4) Build a DataFrame and sort it\n",
    "results_df = pd.DataFrame(results).sort_values(\"RMSE\").reset_index(drop=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection - STRETCH\n",
    "\n",
    "> **This step doesn't need to be part of your Minimum Viable Product (MVP), but its recommended you complete it if you have time!**\n",
    "\n",
    "Even with all the preprocessing we did in Notebook 1, you probably still have a lot of features. Are they all important for prediction?\n",
    "\n",
    "Investigate some feature selection algorithms (Lasso, RFE, Forward/Backward Selection)\n",
    "- Perform feature selection to get a reduced subset of your original features\n",
    "- Refit your models with this reduced dimensionality - how does performance change on your chosen metrics?\n",
    "- Based on this, should you include feature selection in your final pipeline? Explain\n",
    "\n",
    "Remember, feature selection often doesn't directly improve performance, but if performance remains the same, a simpler model is often preferrable. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform feature selection \n",
    "# refit models\n",
    "# gather evaluation metrics and compare to the previous step (full feature set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
